<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="generator" content="Some custom Common Lisp"><meta name="description" content="Blog archives for the fourth quarter of 2019"><link rel="alternate" href="/feed.xml" title="Fanael's random ruminations" type="application/rss+xml"><link rel="stylesheet" href="/static/theme.css"><link rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><title>Blog archives for the fourth quarter of 2019 - Fanael's random ruminations</title></head><body><header id="top-header"><a id="skip-nav" class="at-only" href="#main">Skip to main content</a><span>Fanael's random ruminations</span></header><nav aria-label="Primary"><ul id="top-nav"><li><a href="/">Main page</a></li><li><a href="/archives/">Archives</a></li><li><a href="https://github.com/Fanael/fanael.github.io/">GitHub</a></li><li><a rel="author" href="/pages/about.html">About</a></li></ul></nav><main id="main"><header><h1>Archives for the fourth quarter of 2019</h1></header><nav class="toc" aria-labelledby="toc-label"><span id="toc-label">Table of contents</span><ol><li><a href="#breaking-empty-base-optimization">How to: accidentally break empty base optimization</a></li><li><a href="#blue-ridge-status-update-dec-2019">Blue Ridge status update: December 2019</a></li><li><a href="#hardware-prefetching-in-pentium-iii">Hardware prefetching in Pentium III</a></li><li><a href="#incremental-low-pause-gc">A simple incremental low-pause GC design</a></li></ol></nav><article id="breaking-empty-base-optimization"><header><h2><a href="/breaking-empty-base-optimization.html">How to: accidentally break empty base optimization</a></h2><p>Published on the <time datetime="2019-12-20">20th of December 2019</time></p><p>Topics: <a href="/archives/topic-i-hate-c++.html">i-hate-c++</a></p></header><p>A reasonably common idiom in C++ code is the use of the following or similar class to inhibit move and copy operations, to avoid having to repeat the four <code>delete</code>d functions in every class: </p><pre class="code-block"><span class="cx-language">C++</span>
<code class="cx-numbered"><span class="cx-ln"></span><span><span class="c-k">class</span> noncopyable {
</span><span class="cx-ln"></span><span><span class="c-k">public</span>:
</span><span class="cx-ln"></span><span>    noncopyable(<span class="c-k">const</span> noncopyable&amp;) = <span class="c-k">delete</span>;
</span><span class="cx-ln"></span><span>    noncopyable(noncopyable&amp;&amp;) = <span class="c-k">delete</span>;
</span><span class="cx-ln"></span><span>    noncopyable&amp; <span class="c-k">operator</span>=(<span class="c-k">const</span> noncopyable&amp;) = <span class="c-k">delete</span>;
</span><span class="cx-ln"></span><span>    noncopyable&amp; <span class="c-k">operator</span>=(noncopyable&amp;&amp;) = <span class="c-k">delete</span>;
</span><span class="cx-ln"></span><span><span class="c-k">protected</span>:
</span><span class="cx-ln"></span><span>    noncopyable() = <span class="c-k">default</span>;
</span><span class="cx-ln"></span><span>    ~noncopyable() = <span class="c-k">default</span>;
</span><span class="cx-ln"></span><span>};
</span></code></pre><div class="sidenote" role="note"><p>I'm personally not a huge fan of the <code>noncopyable</code> name, because it describes <em>how</em> instead of <em>why</em>, but that's neither here nor there.</p></div><p>The <code>noncopyable</code> class can be mixed in using inheritance, like so:</p><pre class="code-block"><span class="cx-language">C++</span>
<code class="cx-numbered"><span class="cx-ln"></span><span><span class="c-k">class</span> foo : <span class="c-k">private</span> noncopyable {
</span><span class="cx-ln"></span><span>    <span class="c-c">// …
</span></span><span class="cx-ln"></span><span>};
</span></code></pre><p>So far, so good, but there's more to it than meets the eye.</p><a class="read-full" href="/breaking-empty-base-optimization.html" aria-label="Read the full article: How to: accidentally break empty base optimization">Read the full article…</a></article><article id="blue-ridge-status-update-dec-2019"><header><h2><a href="/blue-ridge-status-update-dec-2019.html">Blue Ridge status update: December 2019</a></h2><p>Published on the <time datetime="2019-12-08">8th of December 2019</time></p><p>Topics: <a href="/archives/topic-garbage-collection.html">garbage-collection</a></p></header><p>Just a "quick" update on the development status of <a href="/incremental-low-pause-gc.html">my low-pause incremental garbage collector</a> (code name <dfn>Blue Ridge</dfn>): it's progressing rather nicely, considering how little motivation my clinically depressed self is able to muster up most days.</p><div class="sidenote" role="note"><p>No points for guessing where the code name comes from.</p></div><p>The garbage collector as currently implemented, in just above 2 thousand lines of code, is already <em>working</em>, that is, it correctly allocates memory and collects garbage, <em>even under address and undefined behavior sanitizers</em>, though it's limited to stop-the-world operation at the moment. This is merely a pragmatic decision on what order to do things in: I'd rather have heap verifiers implemented and tested before diving into incrementality, as catching any potential heap corruptions or invariant violations right away is much preferable to trying to divine the cause of a crash from a core dump.</p><p>That being said, most of the hard work for supporting incremental collections has already been done. Most of the collector's code is written in a way that makes incremental work easy enough, it just happens to not be used in that way yet.</p><p>Performance appears to be fine so far. Pure allocation rate of object that die quickly is limited by how fast the CPU is able to write object data to memory, like in any good moving GC, as the hot path of allocation consists of just advancing a pointer. Collection time is dominated by marking, as one could expect. Throughput, measured by taking the wall-clock time of a program that allocates a linked list of 10 million conses then throws it away, repeating 500 times, is not bad either, being within the same order of magnitude as <a href="https://wiki.openjdk.java.net/display/shenandoah/Main">HotSpot's Shenandoah collector</a> in its passive (stop-the-world only) mode, and <em>beating handily</em> its Parallel and G1 collectors with all four collectors limited to a 1 GB heap, which again, is not unexpected: this is not a very good workload+heap size combination for generational collectors, as they're forced to prematurely tenure conses, which then results in a significant number of painful major collections, while Blue Ridge and Shenandoah aren't affected due to their non-generational nature.</p><p>Blue Ridge in its current state also features <dfn>policies</dfn>, switchable at runtime, that are informed whenever interesting events happen, such as a new region being allocated or the current phase being changed, and that in turn decide whether or not start a cycle, and if so what kind — incremental or stop-the-world — and what regions should belong to the collection set. It is through this mechanism that the aforementioned 1 GB heap limit has been implemented, as Blue Ridge's heap is normally discontinuous, dynamically resizable in either direction and theoretically unlimited.</p><p>All things considered, the development of my garbage collector is progressing well, if slowly due to circumstances beyond my control. I hope I'll be able to have a functionally complete version soon, because that's where the real fun begins: playing around with all the knobs the get the lowest latency, lowest footprint and highest throughput possible.</p><a class="read-full" href="/blue-ridge-status-update-dec-2019.html" aria-label="Read the full article: Blue Ridge status update: December 2019">Read the full article…</a></article><article id="hardware-prefetching-in-pentium-iii"><header><h2><a href="/hardware-prefetching-in-pentium-iii.html">Hardware prefetching in Pentium III</a></h2><p>Published on the <time datetime="2019-10-25">25th of October 2019</time></p><p>Topics: <a href="/archives/topic-microarchitecture-archeology.html">microarchitecture-archeology</a></p></header><p>Nowadays pretty much every processor featuring cache hierarchy has some form of automatic memory prefetch mechanism. In small low-power processors it may be very simplistic and only prefetch if the addresses are increasing, in high-performance processors it may try to predict all sorts of regular and semi-regular patterns, but the basic mechanism <em>will be</em> present in some form.</p><p>We weren't, however, always so lucky. The first mainstream x86 processor with hardware prefetching logic was the Pentium 4 Willamette, first released in November 2000, which used the highly contentious NetBurst microarchitecture. Due to Willamette's mediocrity, Intel didn't kill off their older P6 microarchitecture, and so the hardware prefetching was later supposedly added to the P6-based Pentium III Tualatin (released in June 2001), where its efficacy was disputed due to much lower CPU-chipset bandwidth compared to NetBurst.</p><div class="sidenote" role="note"><p>The P6 microarchitecture introduced in Pentium Pro, in 1995, and used with minor changes in Pentium II and III, is a direct ancestor of Intel's current high-performance x86 microarchitectures — at the time of writing, Ice Lake for mobile, Skylake for everything else. There were many improvements in the last 24 years, and most major bottlenecks were fixed, but the family resemblance is still there.</p><p>P6's direct successor was Pentium M, created for mobile processors due to NetBurst's high power draw rendering it unsuitable for those applications. The Core microarchitecture powering the famous Core 2 series, that let Intel take the performance crown back from AMD after years of humiliation due to their marketing-driven, physics-ignoring bet on NetBurst, was a direct successor of Pentium M.</p></div><p>But how effective was the hardware prefetching in Tualatin, really? And is it really true that Coppermine, the Pentium III revision preceding Tualatin, didn't feature automatic prefetching? Fortunately, by choosing an appropriate test case and using CPU performance counters, it is possible to perform a gray-box test that answers these questions.</p><a class="read-full" href="/hardware-prefetching-in-pentium-iii.html" aria-label="Read the full article: Hardware prefetching in Pentium III">Read the full article…</a></article><article id="incremental-low-pause-gc"><header><h2><a href="/incremental-low-pause-gc.html">A simple incremental low-pause GC design</a></h2><p>Published on the <time datetime="2019-10-12">12th of October 2019</time></p><p>Topics: <a href="/archives/topic-garbage-collection.html">garbage-collection</a></p></header><p>There are too many garbage-collected runtimes using very simplistic designs, such as reference counting or naïve stop the world mark and sweep. These are valid choices in that they're simple and correct, but unfortunately they induce undue costs, such as unpredictable and unbounded pause times.</p><p>I decided to have a go at designing and implementing something better as a part of my custom lisp-dialect implementation, and this blog post is an attempt to describe and organize this design. <strong>Since my toy lisp is single-threaded, so is its garbage collector</strong>. It is possible to extend this design into a parallel one, it just is not one of my goals.</p><p>It should be noted that this design is in no way revolutionary, I'm merely following existing techniques. In particular, <a href="https://wiki.openjdk.java.net/display/shenandoah/Main">Red Hat's excellent Shenandoah</a> has been a major inspiration.</p><a class="read-full" href="/incremental-low-pause-gc.html" aria-label="Read the full article: A simple incremental low-pause GC design">Read the full article…</a></article></main><nav aria-label="Chronological, secondary"><ul id="order-nav"><li class="top"><a href="#skip-nav"><span aria-hidden="true">↑ </span>Top<span aria-hidden="true"> ↑</span></a></li><li class="prev"></li><li><a href="/archives/">Blog archives</a></li><li class="next"></li></ul></nav><footer><ul id="footer"><li>Powered by HTML &amp; CSS</li><li>Copyright © 2019-2022 Fanael Linithien</li><li>Licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a></li></ul></footer></body></html>