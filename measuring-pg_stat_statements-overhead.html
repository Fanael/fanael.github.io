<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="generator" content="Some custom Common Lisp"><meta name="description" content="Measuring the overhead of enabling pg_stat_statements on relatively weak modern-ish hardware"><script defer src="/static/fixes.js"></script><link rel="alternate" href="/feed.xml" title="Fanael's random ruminations" type="application/rss+xml"><link rel="stylesheet" href="/static/theme.css"><link rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><title>Measuring pg_stat_statements overhead - Fanael's random ruminations</title></head><body><header id="top-header"><a id="skip-nav" class="at-only" href="#main">Skip to main content</a><div>Fanael's random ruminations</div></header><nav aria-label="Primary"><ul id="top-nav"><li><a href="/">Main page</a></li><li><a href="/archives/">Archives</a></li><li><a href="https://github.com/Fanael/fanael.github.io/">GitHub</a></li><li><a rel="author" href="/pages/about.html">About</a></li></ul></nav><main id="main"><article><header><h1><a class="section-link" href="#main"><span>Measuring pg_stat_statements overhead</span><span aria-hidden="true"> §</span></a></h1><p>Published on the <time datetime="2023-05-12">12th of May 2023</time></p><p>Topics: <a href="/archives/topic-postgresql.html">postgresql</a></p></header><p><a href="https://www.postgresql.org/docs/current/pgstatstatements.html"><code>pg_stat_statements</code></a> is a fantastically useful PostgreSQL extension that collects execution statistics of all statements executed by the server, to allow the database administrator to monitor and analyze any possible performance issue. For a good reason, it is one of the, if not <em>the</em> most installed extension, and even a cursory internet search will reveal numerous sources extolling its virtues.</p><p>Of course, collecting those statistics has some small performance overhead, which is <a href="https://dba.stackexchange.com/a/303555">widely reported to be negligible</a>. There's nothing wrong with checking the veracity of those claims ourselves, however: hardware and software differences can matter, after all, and the hardware I'm running this database on is not exactly usual.</p><nav class="toc" aria-labelledby="toc-label"><span id="toc-label">Table of contents</span><ol><li><a href="#the-target-machine">The target machine</a></li><li><a href="#the-benchmark">The benchmark</a></li></ol></nav><section id="the-target-machine"><h2><a class="section-link" href="#the-target-machine"><span>The target machine</span><span aria-hidden="true"> §</span></a></h2><p>The particular machine I'm most interested in measuring the overhead on is a repurposed older thin client, so by server standards, it's <em>laughably puny</em>. It features such cutting edge hardware as:</p><ul><li>A dual-core <a href="https://en.wikipedia.org/wiki/Jaguar_(microarchitecture)">AMD Jaguar</a> system-on-chip, clocked at 1.65 GHz.<div class="sidenote" role="note"><p>Fun fact: AMD Jaguar is the CPU microarchitecture powering two of the eighth generation video game consoles, its use outside of embedded spaces is otherwise rare.</p></div></li><li>4 GB of DDR3 RAM, at 1600 MT/s, <em>single-channel</em>. The SoC doesn't support more memory channels; at least it supports ECC.</li><li>128 GB SATA SSD.</li></ul><p>Unlike typical server hardware, it is also completely silent, being 100% passively cooled, and draws very little power, even at full load.</p><div class="sidenote" role="note"><p>Now that I think about it, when compared to some of the smaller cloud instances, this is honestly quite beefy, and there are no noisy neighbors to worry about, and the storage performance is much higher than what basic cloud storage offers, unless you explicitly provision enough throughput and I/O operations per second, which of course costs you extra… huh, I'm starting to think that the entire cloud thing may be a bit of a raw deal.</p></div><p>Software-wise, there's nothing special: just a regular Debian bookworm with PostgreSQL 15.2 installed from Debian's repositories. The PostgreSQL settings are quite vanilla as well, I didn't do anything interesting in <code>postgresql.conf</code> apart from the usual stuff like changing <code>shared_buffers</code>, <code>random_page_cost</code> and some logging settings.</p></section><section id="the-benchmark"><h2><a class="section-link" href="#the-benchmark"><span>The benchmark</span><span aria-hidden="true"> §</span></a></h2><p>What I'm most interested in is what is the worst case overhead I can <em>realistically</em> expect: assume all statements are simple and do very little, if any, I/O. For this reason, I used <a href="https://www.postgresql.org/docs/current/pgbench.html"><code>pgbench</code></a> with scale factor of 40 and in select only mode. With scale factor this small, the database fits entirely not just in RAM, but also in PostgreSQL's shared buffers, while <code>pgbench</code>'s select only mode uses a simple, but still realistic <code>SELECT</code> statement. While one could argue that something like <code>SELECT 1</code> would be even simpler, it does not quite satisfy the criterion of being a realistic query a program would execute against the database.</p><p>With that in mind, let's run <code>pgbench</code> with two client connections — one per thread — for 5 minutes, using prepared statements, then restart the server with <code>pg_stat_statements</code> enabled and do it again.</p><figure><figcaption>Benchmark results, <code>SELECT</code> only</figcaption><div class="holder"><table><thead><tr><th><code>pg_stat_statements</code> state<th>Transactions per second<th>Mean latency<th>Standard deviation<th>Total transactions</tr></thead><tbody><tr><th>off<td>12235<td>0.162 ms<td>0.051 ms<td>3,670,487</tr><tr><th>on<td>11922<td>0.167 ms<td>0.057 ms<td>3,576,490</tr></tbody></table></div></figure><p>We can see that enabling <code>pg_stat_statements</code> resulted in a 2.5% hit to transaction throughput and 3% hit to mean transaction latency. Well worth it, considering the utility of this extension, and in line with the expectations of being negligible.</p><p>We could also try using <code>pgbench</code>'s default transaction type, to see what happens if we add inserts and updates, albeit simple ones still, into the mix. Those operations perform more work than pure selects, for example checking foreign key constraints, updating indexes and appending every data modification to the write-ahead log to ensure crash resilience, so the time spent on collecting statistics should be proportionally smaller.</p><figure><figcaption>Benchmark results, mixed transaction</figcaption><div class="holder"><table><thead><tr><th><code>pg_stat_statements</code> state<th>Transactions per second<th>Mean latency<th>Standard deviation<th>Total transactions</tr></thead><tbody><tr><th>off<td>1402.8<td>1.423 ms<td>0.415 ms<td>420,849</tr><tr><th>on<td>1384.2<td>1.443 ms<td>0.424 ms<td>415,244</tr></tbody></table></div></figure><p>Indeed, the overhead is even smaller now, with only 1.4% drop in throughput and mean latency.</p></section></article></main><nav aria-label="Chronological, secondary"><ul id="order-nav"><li class="top"><a href="#skip-nav"><span aria-hidden="true">↑ </span>Top<span aria-hidden="true"> ↑</span></a></li><li class="prev"><a rel="prev" href="/you-can-embrace-extend-extinguish-free-software.html"><span aria-hidden="true">← </span>Older</a></li><li><a href="/archives/">Blog archives</a></li><li class="next"></li></ul></nav><footer><ul id="footer"><li><a href="/pages/offline-mode.html">Offline mode</a></li><li>Powered by HTML &amp; CSS</li><li>Copyright © 2019-2023 Fanael Linithien</li><li>Licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a></li></ul></footer></body></html>