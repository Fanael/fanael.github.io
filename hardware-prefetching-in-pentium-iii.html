<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><meta http-equiv="Content-Security-Policy" content="default-src 'self'; object-src 'none'"><meta name="generator" content="Some custom Common Lisp"><meta name="description" content="Determining the existence and discovering the basic characteristics of the hardware prefetcher in Pentium III"><link rel="alternate" href="/feed.xml" title="Fanael's random ruminations" type="application/rss+xml"><link rel="stylesheet" href="/static/theme.css"><link rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><title>Hardware prefetching in Pentium III - Fanael's random ruminations</title></head><body><a id="skip-nav" href="#main">Skip to main content</a><header id="mainheader">Fanael's random ruminations</header><nav aria-label="Primary"><ul id="navmenu"><li><a href="/">Main page</a></li><li><a href="/archives/">Archives</a></li><li><a href="https://github.com/Fanael/fanael.github.io/">GitHub</a></li><li><a rel="author" href="/pages/about.html">About</a></li></ul></nav><main id="main"><article><header><h1><a class="section-header-link" href="#main">§</a>Hardware prefetching in Pentium III</h1><p>Published on the <time datetime="2019-10-25">25th of October 2019</time></p><p>Topics: <a href="/archives/topic-microarchitecture-archeology.html">microarchitecture-archeology</a></p></header><p>Nowadays pretty much every processor featuring cache hierarchy has some form of automatic memory prefetch mechanism. In small low-power processors it may be very simplistic and only prefetch if the addresses are increasing, in high-performance processors it may try to predict all sorts of regular and semi-regular patterns, but the basic mechanism <em>will be</em> present in some form.</p><p>We weren't, however, always so lucky. The first mainstream x86 processor with hardware prefetching logic was the Pentium 4 Willamette, first released in November 2000, which used the highly contentious NetBurst microarchitecture. Due to Willamette's mediocrity, Intel didn't kill off their older P6 microarchitecture, and so the hardware prefetching was later supposedly added to the P6-based Pentium III Tualatin (released in June 2001), where its efficacy was disputed due to much lower CPU-chipset bandwidth compared to NetBurst.</p><aside><p>The P6 microarchitecture introduced in Pentium Pro, in 1995, and used with minor changes in Pentium II and III, is a direct ancestor of Intel's current high-performance x86 microarchitectures — at the time of writing, Ice Lake for mobile, Skylake for everything else. There were many improvements in the last 24 years, and most major bottlenecks were fixed, but the family resemblance is still there.</p><p>P6's direct successor was Pentium M, created for mobile processors due to NetBurst's high power draw rendering it unsuitable for those applications. The Core microarchitecture powering the famous Core 2 series, that let Intel take the performance crown back from AMD after years of humiliation due to their marketing-driven, physics-ignoring bet on NetBurst, was a direct successor of Pentium M.</p></aside><p>But how effective was the hardware prefetching in Tualatin, really? And is it really true that Coppermine, the Pentium III revision preceding Tualatin, didn't feature automatic prefetching? Fortunately, by choosing an appropriate test case and using CPU performance counters, it is possible to perform a gray-box test that answers these questions.</p><nav class="toc" aria-labelledby="toc-label"><span id="toc-label">Table of contents</span><ol><li><a href="#test">The test</a></li><li><a href="#results">The results</a><ol><li><a href="#results-coppermine">Coppermine</a></li><li><a href="#results-tualatin">Tualatin</a></li><li><a href="#results-dothan">Dothan</a></li></ol></li><li><a href="#conclusion">The conclusion</a></li></ol></nav><section id="test"><h2><a class="section-header-link" href="#test">§</a>The test</h2><p>The thing I want to test is whether or not Pentium III's prefetcher, if existent and effective, can handle accessing memory linearly with large variable strides. The first algorithm with such an access pattern that came to my mind was <a href="https://en.wikipedia.org/wiki/Shellsort">Shell sort</a>. When used with the <a href="https://en.wikipedia.org/wiki/Smooth_number">3-smooth numbers</a> (i.e. numbers of the form <i>2<sup>p</sup>3<sup>q</sup></i>, with natural <var>p</var> and <var>q</var>) as the gap sequence, its time complexity is <i>O(nlog<sup>2</sup>n)</i>, which is practical even for large values of <var>n</var>.</p><p>As a comparison baseline the obvious choice is then <a href="https://en.wikipedia.org/wiki/Heapsort">heap sort</a>, due to its infamy for being <em>extremely</em> cache-hostile and already being available in the C++ standard library. In fact, if comparisons and swaps are cheap, heap sort's cache hostility can and does make up for its theoretical complexity advantage, making it not much faster than 3-smooth Shell sort. On my Core i5-4590 (Haswell) the difference between the two algorithms is indeed less than a factor of two:</p><pre class="codeblock" data-code-language="Shell (interactive)"><samp>$ g++ -O3 p3-prefetch-shell-sort.cc &amp;&amp; time ./a.out # heap sort
./a.out  2,77s user 0,00s system 99% cpu 2,771 total
$ g++ -O3 -DUSE_SHELL_SORT p3-prefetch-shell-sort.cc &amp;&amp; time ./a.out # Shell sort
./a.out  4,52s user 0,00s system 99% cpu 4,517 total</samp></pre><p>The implementation of Shell sort has been lifted from Wikipedia and C++-ified with no other significant changes:</p><pre class="codeblock" data-code-language="C++"><code><span class="c-k">void</span> shell_sort(std::<span class="c-k">uint32_t</span>* array, std::<span class="c-k">size_t</span> length)
{
    <span class="c-k">if</span>(length &lt;= <span class="c-m">1</span>) {
        <span class="c-k">return</span>;
    }

    <span class="c-k">auto</span> current_gap = std::find_if(std::begin(gaps), std::end(gaps),
        [&amp;](std::<span class="c-k">size_t</span> gap){<span class="c-k">return</span> gap &gt;= length;});
    <span class="c-k">do</span> {
        --current_gap;
        <span class="c-k">const</span> <span class="c-k">auto</span> gap = *current_gap;
        <span class="c-k">for</span>(std::<span class="c-k">size_t</span> i = gap; i &lt; length; ++i) {
            <span class="c-k">auto</span> temp = std::move(array[i]);
            std::<span class="c-k">size_t</span> j = i;
            <span class="c-k">for</span>(; j &gt;= gap &amp;&amp; array[j - gap] &gt; temp; j -= gap) {
                array[j] = std::move(array[j - gap]);
            }
            array[j] = std::move(temp);
        }
    } <span class="c-k">while</span>(current_gap &gt; std::begin(gaps));
}
</code></pre><p><a href="/static/p3-prefetch-shell-sort.cc">The complete source of the benchmark program</a> is available under <a href="https://creativecommons.org/publicdomain/zero/1.0/">the CC0 license</a>.</p><aside><p>In practice, neither algorithm is a very good choice for general-purpose sorting; instead, use something <em>really</em> cache-friendly <em>and</em> theoretically efficient, like introsort or merge sort, one of these is almost certainly used to implement the sorting routine in the standard library of your language of choice already, so just use that. Shell sort and heap sort were only chosen here for their memory access patterns.</p></aside><p>With that code, a Coppermine Pentium III at 1 GHz (thanks to <b>daemon32</b> for running the test!), a Tualatin Pentium III at 1.13 GHz, a Dothan Pentium M at 1.6 GHz for comparison purposes, GCC 8, Intel's performance event register reference, and the excellent Linux <cite class="program-name">perf</cite> tool, let's go measuring.</p></section><section id="results"><h2><a class="section-header-link" href="#results">§</a>The results</h2><p>There is a problem. The Intel performance monitoring event reference doesn't mention anything about prefetching in its P6 chapter! Prefetching events are mentioned in the Pentium M reference, however, and considering P6 family history, it's not unreasonable to believe the same events would be used in Pentium III. These events are, in syntax suitable for <code>perf stat -e</code>, <kbd>cpu/event=0xf0,name=upward-prefetches/</kbd> and <kbd>cpu/event=0xf8,name=downward-prefetches/</kbd>. They count the number of <em>prefetch requests</em>, and therefore the number of prefetched <em>cache lines</em>. This will be important later on.</p><p>So first things first: <strong>these events don't report anything on Coppermine, always showing zeros</strong>. This adds credence to the idea that Coppermine and earlier P6 models didn't have hardware prefetching unit. On Tualatin, however, things are more interesting, so without further ado, let's dive into the performance counter stats!</p><section id="results-coppermine"><h3><a class="section-header-link" href="#results-coppermine">§</a>Coppermine</h3><figure><figcaption>Performance event counts for <em>heap</em> sort on Coppermine</figcaption><div class="holder"><table class="perf-stat"><thead><tr><th>Event<th>Value<th>Unit<th>Comment<th>Time active</tr></thead><tbody><tr><th>Task clock<td>33,276.77<td>msec<td>0.999 CPUs utilized<td></tr><tr><th>Context switches<td>204<td><td>0.006 K/sec<td></tr><tr><th>Page faults<td>14,715<td><td>0.442 K/sec<td></tr><tr><th>Cycles<td>32,854,157,356<td><td>0.987 GHz<td>20.00%</tr><tr><th>Stalled cycles, frontend<td>25,399,721,497<td><td>77.31% frontend cycles idle<td>20.01%</tr><tr><th>Instructions<td>7,109,652,282<td><td>0.22 instructions per cycle<br>3.57 stalled cycles per instruction<td>20.01%</tr><tr><th>Branches<td>1,188,575,659<td><td>35.718 M/sec<td>20.01%</tr><tr><th>Mispredicted branches<td>196,353,276<td><td>16.52% of all branches<td>20.00%</tr><tr><th>Elapsed time<td>33.307<td>seconds<td><td></tr></tbody></table></div></figure><figure><figcaption>Performance event counts for <em>shell</em> sort on Coppermine</figcaption><div class="holder"><table class="perf-stat"><thead><tr><th>Event<th>Value<th>Unit<th>Comment<th>Time active</tr></thead><tbody><tr><th>Task clock<td>133,899.70<td>msec<td>0.999 CPUs utilized<td></tr><tr><th>Context switches<td>647<td><td>0.005 K/sec<td></tr><tr><th>Page faults<td>14,717<td><td>0.110 K/sec<td></tr><tr><th>Cycles<td>132,163,280,671<td><td>0.987 GHz<td>20.00%</tr><tr><th>Stalled cycles, frontend<td>96,185,812,551<td><td>72.78% frontend cycles idle<td>20.00%</tr><tr><th>Instructions<td>53,356,713,225<td><td>0.40 instructions per cycle<br>1.80 stalled cycles per instruction<td>20.00%</tr><tr><th>Branches<td>8,501,189,300<td><td>63.489 M/sec<td>20.00%</tr><tr><th>Mispredicted branches<td>269,043,077<td><td>3.16% of all branches<td>20.00%</tr><tr><th>Elapsed time<td>133.983<td>seconds<td><td></tr></tbody></table></div></figure><p>The first observation: it's <em>slow</em>. But more importantly, it tells us <em>why</em> it is slow: the out-of-order engine is full, but instructions cannot retire because they're still waiting on memory accesses to complete (as there are no other significant sources of stalls in this program), which stalls the front-end too. Heap sort stalls a lot because it's heap sort; Shell sort stalls a lot, albeit a bit less, because with large gap sizes, at least until they get small enough to resemble insertion sort cache-wise, the program performs lots of memory accesses to far away addresses that either haven't had a chance to get into cache yet, or have already been evicted to make room for newer ones, and there's no prefetching to do it ahead-of-time.</p></section><section id="results-tualatin"><h3><a class="section-header-link" href="#results-tualatin">§</a>Tualatin</h3><figure><figcaption>Performance event counts for <em>heap</em> sort on Tualatin</figcaption><div class="holder"><table class="perf-stat"><thead><tr><th>Event<th>Value<th>Unit<th>Comment<th>Time active</tr></thead><tbody><tr><th>Task clock<td>31,190.69<td>msec<td>0.993 CPUs utilized<td></tr><tr><th>Page faults<td>1,429<td><td>0.046 K/sec<td></tr><tr><th>Cycles<td>33,344,788,971<td><td>1.069 GHz<td>28.53%</tr><tr><th>Stalled cycles, frontend<td>25,490,259,991<td><td>76.44% frontend cycles idle<td>28.60%</tr><tr><th>Instructions<td>7,084,795,042<td><td>0.21 instructions per cycle<br>3.60 stalled cycles per instruction<td>28.60%</tr><tr><th>Branches<td>1,221,344,046<td><td>39.157 M/sec<td>28.59%</tr><tr><th>Mispredicted branches<td>195,036,348<td><td>15.97% of all branches<td>28.59%</tr><tr><th>Upward prefetches<td>71,322,504<td><td>2.287 M/sec<td>28.57%</tr><tr><th>Downward prefetches<td>0<td><td>0.000 K/sec<td>28.51%</tr><tr><th>Elapsed time<td>31.404<td>seconds<td><td></tr></tbody></table></div></figure><figure><figcaption>Performance event counts for <em>shell</em> sort on Tualatin</figcaption><div class="holder"><table class="perf-stat"><thead><tr><th>Event<th>Value<th>Unit<th>Comment<th>Time active</tr></thead><tbody><tr><th>Task clock<td>72,946.84<td>msec<td>0.991 CPUs utilized<td></tr><tr><th>Page faults<td>1,434<td><td>0.020 K/sec<td></tr><tr><th>Cycles<td>78,228,149,161<td><td>1.072 GHz<td>28.58%</tr><tr><th>Stalled cycles, frontend<td>43,812,136,162<td><td>56.01% frontend cycles idle<td>28.58%</tr><tr><th>Instructions<td>53,121,702,516<td><td>0.68 instructions per cycle<br>0.82 stalled cycles per instruction<td>28.57%</tr><tr><th>Branches<td>8,465,544,250<td><td>116.051 M/sec<td>28.58%</tr><tr><th>Mispredicted branches<td>264,197,085<td><td>3.12% of all branches<td>28.56%</tr><tr><th>Upward prefetches<td>704,750,223<td><td>9.661 M/sec<td>28.55%</tr><tr><th>Downward prefetches<td>0<td><td>0.000 K/sec<td>28.58%</tr><tr><th>Elapsed time<td>73.609<td>seconds<td><td></tr></tbody></table></div></figure><p>Heap sort is still being heap sort, but <strong>Shell sort is almost two times as fast</strong>, and the only relevant hardware difference was the introduction of hardware prefetching in Tualatin. It's also obvious from these numbers that Tualatin's hardware prefetching <strong>only considers ascending address sequences</strong>, as the downward prefetch counter is stuck at 0.</p><p>The prefetch rate, that is cache line size — the original P6 is a weird member of the P6 family, as <strong>its cache line size is 32 bytes</strong>, not 64 as in all of its descendants! — times the number of prefetch requests divided by time, is about 295 MB/s. Since the array is 60 million bytes, or slightly over 57 MB, and only gap sizes of 8 and below touch adjacent cache lines, my educated guess is that it's likely the prefetcher <em>does</em> handle variable strides. Sure, it's unlikely to be perfect. Sure, the memory bandwidth is limited, with the 133 MHz front-side bus the theoretical maximum is about a gigabyte per second, less in practice. But the prefetcher is there, handles variable strides, and does it well enough that at least in this case it greatly improves performance.</p></section><section id="results-dothan"><h3><a class="section-header-link" href="#results-dothan">§</a>Dothan</h3><p>This is not a Pentium III. It's a Pentium M, it's not even the original P6 anymore, it contains many improvements compared to its predecessor, most of which survive to this day in modern P6 descendants. It also has significantly bigger cache and faster processor-chipset, and thus processor-memory, interface. But let's still see how it handles this test, because this is the CPU for which the performance events used are documented, and out of sheer curiosity.</p><figure><figcaption>Performance event counts for <em>heap</em> sort on Dothan Pentium M</figcaption><div class="holder"><table class="perf-stat"><thead><tr><th>Event<th>Value<th>Unit<th>Comment<th>Time active</tr></thead><tbody><tr><th>Task clock<td>16,842.52<td>msec<td>0.996 CPUs utilized<td></tr><tr><th>Page faults<td>1,433<td><td>0.085 K/sec<td></tr><tr><th>Cycles<td>26,310,833,013<td><td>1.562 GHz<td>28.57%</tr><tr><th>Stalled cycles, frontend<td>18,575,088,740<td><td>70.60% frontend cycles idle<td>28.58%</tr><tr><th>Instructions<td>7,093,179,520<td><td>0.27 instructions per cycle<br>2.62 stalled cycles per instruction<td>28.56%</tr><tr><th>Branches<td>1,217,221,905<td><td>72.271 M/sec<td>28.56%</tr><tr><th>Mispredicted branches<td>207,078,239<td><td>17.01% of all branches<td>28.55%</tr><tr><th>Upward prefetches<td>21,031,331<td><td>1.249 M/sec<td>28.57%</tr><tr><th>Downward prefetches<td>92,661,140<td><td>5.502 M/sec<td>28.60%</tr><tr><th>Elapsed time<td>16.903<td>seconds<td><td></tr></tbody></table></div></figure><figure><figcaption>Performance event counts for <em>shell</em> sort on Dothan Pentium M</figcaption><div class="holder"><table class="perf-stat"><thead><tr><th>Event<th>Value<th>Unit<th>Comment<th>Time active</tr></thead><tbody><tr><th>Task clock<td>33,594.70<td>msec<td>0.996 CPUs utilized<td></tr><tr><th>Page faults<td>1,435<td><td>0.043 K/sec<td></tr><tr><th>Cycles<td>52,612,387,270<td><td>1.566 GHz<td>28.59%</tr><tr><th>Stalled cycles, frontend<td>23,082,925,885<td><td>43.87% frontend cycles idle<td>28.55%</tr><tr><th>Instructions<td>53,098,993,093<td><td>1.01 instructions per cycle<br>0.43 stalled cycles per instruction<td>28.55%</tr><tr><th>Branches<td>8,469,337,848<td><td>252.103 M/sec<td>28.57%</tr><tr><th>Mispredicted branches<td>290,400,768<td><td>3.43% of all branches<td>28.61%</tr><tr><th>Upward prefetches<td>355,720,357<td><td>10.589 M/sec<td>28.59%</tr><tr><th>Downward prefetches<td>12,126<td><td>0.361 K/sec<td>28.57%</tr><tr><th>Elapsed time<td>33.716<td>seconds<td><td></tr></tbody></table></div></figure><p>Both algorithms benefit from the increased cache, but Shell sort more so. This is also the first time we've seen more than 1 instruction per cycle in this post. Not that it's somehow an great result: my Haswell box mentioned earlier executes 2.4 instructions per cycle in that same test, for whoever is wondering, but that's a processor released 10 years later than this Pentium M.</p><p>The total number of upward prefetches, when expressed in <em>bytes</em> — Pentium M has now-standard 64-byte cache lines — is almost exactly the same as on Tualatin, confirming that the upward prefetch counter indeed works there.</p></section></section><section id="conclusion"><h2><a class="section-header-link" href="#conclusion">§</a>The conclusion</h2><p>This test shows that the legends are true. Coppermine doesn't have automatic hardware prefetching, and thus presumably Katmai and older P6 processors don't either. It was introduced in a limited, but functional, form in Tualatin: hardware prefetching only works for ascending addresses, and is limited by slow memory interface, but can handle variable strides, and even the undocumented performance events appear to function correctly.</p></section></article></main><nav aria-label="Chronological, secondary"><ul id="prevnext"><li class="top"><a href="#skip-nav">↑ Top ↑</a></li><li class="prev"><a rel="prev" href="/incremental-low-pause-gc.html">← Older</a></li><li><a href="/archives/">Blog archives</a></li><li class="next"><a rel="next" href="/blue-ridge-status-update-dec-2019.html">Newer →</a></li></ul></nav><footer><ul id="footerstuff"><li>Powered by HTML &amp; CSS</li><li>Copyright © 2019-2021 Fanael Linithien</li><li>Licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a></li></ul></footer></body></html>